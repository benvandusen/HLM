---
title: "R markdown test"
author: "BVD"
date: "9/18/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First we need to build the HLM models in R (done)
Then do the AIC testing (not possible. We'll do a simple variance explained argument)
Then do assumption checking
Then build descriptives for gain aggregated and disagregated and add the means to the descriptives table

---
title: "Equity analysis"
output: html_document
---

Load stuff (There are some packages that we don't need here, but I didn't clean them up. Sorry.)
```{r message=FALSE, warning=FALSE}
#load("~/Box Sync/work/Research/R stuff/hmiout40") #Ben's computer
load("~/Documents/LASSO Data/Old/hmiout40")
library("ggplot2")
library(gvlma)
library("HLMdiag")
library("DHARMa")
library("car") #for the Levene test which we will not discuss here
library("Matrix")
library(mitools)
library(stargazer)
library(lme4)
library(nlme)
library(mice)
library(mitml)
library(multcomp)
library(foreach)
library(ggplot2)
library(stringr)
library(dplyr)  #I load dplyr last because some of its functions (select) will be masked by plyr and it is a PITA to debug
```

Creating mitml and extra variables
```{r}
MIdata<-mids2mitml.list(hmi.out40) #converts file type

thing <- list()
for (i in 1:10){
  temp <- MIdata[[i]]
  class_means <- temp %>% group_by(crse_id) %>% summarise(pre_mean_class = mean(pre_scor))
  class_means$class_pre_cent <- mean(class_means$pre_mean_class) - class_means$pre_mean_class
  temp <- left_join(temp,class_means, by="crse_id")
  temp$stud_pre_cent <- temp$pre_mean_class - temp$pre_scor
  temp$stud_pre_grand <- temp$pre_scor-mean(temp$pre_scor)
  temp$gain <- temp$pst_scor - temp$pre_scor
  temp$collabnla <- ifelse(temp$colablrn==1,ifelse(temp$used_las==0,1,0),0)
  temp$coll <- temp$collabnla + temp$used_las
  #assign(df.names[i], temp)
  thing[[i]] <- temp
  }
MIdata <- as.mitml.list(thing)
```

Models (Note, we can't actually use these since they don't work with the with function)
```{r}
mod1 <- (gain~1 + (1|crse_id))
mod2 <- (gain~1 + used_las + collabnla + (1|crse_id))
mod3 <- (gain~1 + stud_pre_cent+  used_las + collabnla + (1|crse_id))
mod4 <- (gain~1 + stud_pre_cent+  used_las + collabnla + (1+ stud_pre_cent|crse_id))
mod5 <- (gain~1 + stud_pre_cent+  used_las + collabnla + class_pre_cent + (1|crse_id))
mod6 <- (gain~1 + stud_pre_cent+  used_las + collabnla + class_pre_cent + (1+ stud_pre_cent|crse_id))
```

Run HLM models
```{r message=FALSE, warning=FALSE}
HLM1<-with(MIdata,{lmer(gain~1 + (1|crse_id))})
HLM2<-with(MIdata,{lmer(gain~1 + used_las + collabnla + (1|crse_id))})
HLM3<-with(MIdata,{lmer(gain~1 + stud_pre_cent+  used_las + collabnla + (1|crse_id))})
HLM4<-with(MIdata,{lmer(gain~1 + stud_pre_cent+  used_las + collabnla + (1+ stud_pre_cent|crse_id))})
HLM5<-with(MIdata,{lmer(gain~1 + stud_pre_cent+  used_las + collabnla + class_pre_cent + (1|crse_id))})
HLM6<-with(MIdata,{lmer(gain~1 + stud_pre_cent+  used_las + collabnla + class_pre_cent + (1+ stud_pre_cent|crse_id))})
```

```{r message=FALSE, warning=FALSE}
HLM3.1<-with(MIdata,{lmer(gain~1 + stud_pre_grand+  used_las + collabnla + (1|crse_id))})
HLM4.1<-with(MIdata,{lmer(gain~1 + stud_pre_grand+  used_las + collabnla + (1+ stud_pre_grand|crse_id))})
HLM5.1<-with(MIdata,{lmer(gain~1 + stud_pre_grand+  used_las + collabnla + class_pre_cent + (1|crse_id))})
HLM6.1<-with(MIdata,{lmer(gain~1 + stud_pre_grand+  used_las + collabnla + class_pre_cent + (1+ stud_pre_cent|crse_id))})
```

Run MLR models
```{r}
MLR1<-with(MIdata,{lm(gain~1)})
MLR2<-with(MIdata,{lm(gain~1 + used_las + collabnla)})
MLR3<-with(MIdata,{lm(gain~1 + stud_pre_cent+  used_las + collabnla)})
MLR4<-with(MIdata,{lm(gain~1 + stud_pre_cent+  used_las + collabnla)})
MLR5<-with(MIdata,{lm(gain~1 + stud_pre_cent+  used_las + collabnla + class_pre_cent)})
MLR6<-with(MIdata,{lm(gain~1 + stud_pre_cent+  used_las + collabnla + class_pre_cent)})
```

HLM Model outputs
```{r}
testEstimates(HLM1, var.comp=TRUE)
testEstimates(HLM2, var.comp=TRUE)
testEstimates(HLM3, var.comp=TRUE)
testEstimates(HLM4, var.comp=TRUE)
testEstimates(HLM5, var.comp=TRUE)
testEstimates(HLM6, var.comp=TRUE)
```

```{r}
testEstimates(HLM1, var.comp=TRUE)
testEstimates(HLM2, var.comp=TRUE)
testEstimates(HLM3.1, var.comp=TRUE)
testEstimates(HLM4.1, var.comp=TRUE)
testEstimates(HLM5.1, var.comp=TRUE)
testEstimates(HLM6.1, var.comp=TRUE)
```

MLR Model outputs
```{r}
testEstimates(MLR1, var.comp=TRUE)
testEstimates(MLR2, var.comp=TRUE)
testEstimates(MLR3, var.comp=TRUE)
testEstimates(MLR4, var.comp=TRUE)
testEstimates(MLR5, var.comp=TRUE)
testEstimates(MLR6, var.comp=TRUE)
```

Assumption checking as recommended here: https://ademos.people.uic.edu/Chapter18.html
Note: I think we may just need to do this for each of the 10 datasets independently.

Run 10 HLM 3 models
```{r}
D1 <- lmer(mod3,data=MIdata[[1]])
```



Linearity... check residuals following this guys solution?
https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=4284&context=etd
https://stackoverflow.com/questions/33859440/residual-plots-for-multiple-imputation-using-mice-package-in-r
https://biologyforfun.wordpress.com/2014/04/16/checking-glm-model-assumptions-in-r/

Linearity (we pass)
```{r}
plot(D1)
```

X variables are not correlated to the residuals (we pass)
```{r}
cor.test(resid(D1), MIdata[[1]]$pre_scor) 
cor.test(resid(D1), MIdata[[1]]$used_las) 
cor.test(resid(D1), MIdata[[1]]$collabnla) 
```

https://ademos.people.uic.edu/Chapter18.html
homogenety of variance we pass with variance, but not variance^2 (don't pass?) 
Maybe not required for HLM: https://stats.stackexchange.com/questions/77891/checking-assumptions-lmer-lme-mixed-models-in-r
https://stats.stackexchange.com/questions/255546/test-homogeneity-in-lmer-models

```{r}
MIdata[[1]]$Model.F.Res<- residuals(D1) #extracts the residuals and places them in a new column in our original data table
MIdata[[1]]$Abs.Model.F.Res <-abs(MIdata[[1]]$Model.F.Res) #creates a new column with the absolute value of the residuals
MIdata[[1]]$Model.F.Res2 <- MIdata[[1]]$Abs.Model.F.Res^2 #squares the absolute values of the residuals to provide the more robust estimate

Levene.Model.F <- lm(Model.F.Res ~ crse_id, data=MIdata[[1]]) #ANOVA of the residuals
anova(Levene.Model.F) #displays the results

Levene.Model.F2 <- lm(Model.F.Res2 ~ crse_id, data=MIdata[[1]]) #ANOVA of the squared residuals
anova(Levene.Model.F2) #displays the results

boxplot(MIdata[[1]]$Model.F.Res ~ MIdata[[1]]$crse_id)
boxplot(MIdata[[1]]$Model.F.Res2 ~ MIdata[[1]]$crse_id)
```

Assumption of Normality or residuals (we pass)
```{r}
qqmath(D1) #id: identifies values that may be exerting undue influence on the model (i.e. outliers) 
```




Try using Dharma: https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html
```{r}
simulationOutput <- with(MIdata[[1]],{simulateResiduals(fittedModel = D1, n = 250)})
plot(simulationOutput)
testUniformity(simulationOutput = simulationOutput)

```


HLMdiag version of diagnostics
```{r}
library(HLMdiag)

resid1_D1 <- HLMresid(D1, level = 1, type = "LS", standardize = TRUE)
head(resid1_D1)

qplot(x= MIdata[[1]]$pre_scor, y = LS.resid, data = resid1_D1, geom = c("point", "smooth")) +ylab ("LS level-1 residuals") #L1 residuals vs. prescore

qplot(x= MIdata[[1]]$gain, y = LS.resid, data = resid1_D1, geom = c("point", "smooth")) +ylab ("LS level-1 residuals") #L1 residuals vs. gain

resid1_sem_D1 <- HLMresid(D1, level = 1, type = "LS", standardize = "semi") #use to test for homoscedasticity in L1
head(resid1_sem_D1) 

qplot(x= MIdata[[1]]$pre_scor, y = semi.std.resid, data = resid1_sem_D1) + geom_smooth(method = "lm") +ylab ("semi-standardized residuals") +xlab("Prescore") #L1 semi-standardized residuals vs. prescore. Looks good for homoscedasticity and linearity

qplot(x= MIdata[[1]]$gain, y = semi.std.resid, data = resid1_sem_D1) + geom_smooth(method = "lm") +ylab ("semi-standardized residuals") +xlab("gain") #L1 semi-standardized residuals vs. gain. Looks good for homoscedasticity and linearity

ssresid <- na.omit(resid1_sem_D1$semi.std.resid)
ggplot_qqnorm(x = ssresid, line = "rlm") #L1 semi-standardized residual q-q plot. This checks for normality, and we look good.

#Now level 2 stuff
resid2_D1 <- HLMresid(object = D1, level = "crse_id") #This doesn't appear to be pulling the L2 residuals for some reason.
head(resid2_D1)

ssresid2 <- na.omit(resid2_D1$standLRT)
ggplot_qqnorm(x = ssresid2, line = "rlm")
```


http://r-statistics.co/Assumptions-of-Linear-Regression.html

Creating groups for final model
```{r}
WM=c(1,0,0,0,0,0,0,0,0,0,0,0,0)
WMC=c(1,0,1,0,0,0,0,0,0,0,0,0,0)
WMLA=c(1,0,0,1,0,0,0,0,0,0,0,0,0)
BM=c(1,0,0,0,0,1,0,0,0,0,0,0,0)
BMC=c(1,0,1,0,0,1,0,0,0,0,1,0,0)
BMLA=c(1,0,0,1,0,1,0,0,0,1,0,0,0)
WF=c(1,0,0,0,0,0,1,0,0,0,0,0,0)
WFC=c(1,0,1,0,0,0,1,0,0,0,0,0,1)
WFLA=c(1,0,0,1,0,0,1,0,0,0,0,1,0)
BF=c(1,0,0,0,0,1,1,0,0,0,0,0,0)
BFC=c(1,0,1,0,0,1,1,0,0,0,1,0,1)
BFLA=c(1,0,0,1,0,1,1,0,0,1,0,1,0)

contrast.formulas <-rbind('White Male'=WM, 'White Male Collab'=WMC, 'White Male LA'=WMLA,
                          'Black Male'=BM, 'Black Male Collab'=BMC, 'Black Male LA'=BMLA,
                          'White Female'=WF,'White Female Collab'=WFC, 'White Female LA'=WFLA,
                          'Black Female'=BF,'Black Female Collab'=BFC, 'Black Female LA'=BFLA)
```

